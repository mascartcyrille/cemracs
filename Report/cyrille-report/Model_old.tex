In this study we are interrested in a large (possibly infinite) network of interacting integrate and fire neurons. \cite{lewis_dynamics_2003} and \cite{ostojic_synchronization_2009} proposed an equation describing the evolution in time of the potential $V_i$ of the $i^{th}$ neuron in a network of N
	\begin{equation}
		\hspace*{-2cm} \begin{cases}
			\frac{d}{dt}V_i(t)=-\lambda V_i(t)+\frac{\alpha}{N}\sum_j\sum_i\delta_0(t-\tau_k^j)+\frac{\beta}{N}\sum_{j\neq i}V_j(t)+I_i^{ext}(t)+\sigma\mu_i(t) &\quad\text{if }V_i<V_T\\
			V_i(t^+)=V_R & \quad\text{if V}_i\text{ reaches V}_T\text{ at time t}\\
		\end{cases}
	\end{equation}
\cite{ostojic_synchronization_2009} and \cite{delarue:hal-00747565} gives more detail about the physical signification of the terms in the equation. As an overview, $V_i(t)$ is the function associated with the evolution in time of the potential of the membrane of the neuron i, $I_i^{ext}(t)+\sigma\mu_i(t)$ is the effect of electrical currents outside of the studied network (mean value + gaussian white noise), $\frac{\alpha}{N}\sum_j\sum_i\delta_0(t-\tau_k^j)$ 
Here we are interested in the 



\subsection{What the equation is composed of}
	The equation is derived from the Fokker-Planck-Kolmogorov equation. We are going to describe the components of this equation by explaining the behaviour of a neuron. First the potential, mentionned a bit earlier, that is denoted V in the equation. It varies between two values, $V_R$ and $V_T$, respectively a reset value and a threshold value. Whenever the potential increases at or over the $V_T$ threshold, it is immediately reset to $V_R$. This event is unconditionnaly followed by the emission of a spike, which can be viewed as a transmission of the potential from a neuron to others. It is worth noting that the model presented here is incomplete as it does not formally forbid the emission of another spike as it is the case for biological neurons. Indeed, just after spiking a neuron enters in a refractory state, during a predefined period, during which it is impossible for the neuron to spike again. That being said, a refractory period spontaneously emerges from the model \emph{de facto} as the potential of a neuron is reset immediately after spiking. Under this condition, a tremendous amount of external potentials would be needed for a neuron to spike again.\\
	Speaking of external potentials, they are the results of other neuron's spiking in the network, and are modeled here by the Dirac terms in equation (1). Basically, whenever a neuron j in the network of N neurons spikes, the potential of the neuron i in the network receives a \emph{kick} of size $\frac{\alpha}{N}$. Four remarks here: the spikes are instantaneous, the $\alpha$ is constant for the whole system in the equation, the network is a complete graph and the potential of a neuron at a given time depends on all the previous spikes it has received since the dawn of times (or at least since its creation).\\
	The instantaneous hallmark of the spiking part of the Integrate\&Fire model is perfectly assumed, is especially appropriate for extracellularly recorded neural signals. Spikes are stereotyped events: they are commonly viewed as a realization of a 'point process' due to the all-or-none nature of the action potential and its effects on the postsynaptic neurons. On the other hand it is more and more believed that the delay between a spike emission and its receiption plays a role in the encoding of the information. Some models have been conceived to fill this gap, but are not discussed here. If interrested, you can look at [INSERT HERE PUBLICATIONS ABOUT I\&F MODELS WITH DELAYS].\\
	About the weight of the \emph{kicks}, they are constant in the base equation described above, but one of the main goals of this project was to study the case where the weight depends on the neuron. The $\alpha$ then becomes $\alpha^{i,j}$. As a starting point the value of the $\alpha^{i,j}$ is a Bernouilli of a parameter \emph{p}. In this case the connectivity of the graph decreases, as well as the mean action potential received from presynaptic neurons. This can be compensated by the introduction of a constant term in front of the Bernoulli to increase $\alpha^{i,j}$ value.
	Actually the parameter p of the Bernoulli is equivalent to a probability of connection between two neurons. This is more realistic as the graph of neurons in the brain is really sparse on average [INSERT VALUES OF CONNEXION IN BRAIN]. An important characteristic of neurons in real brains is the type of signal they transmit: excitatory (the signal increases the action potential of postsynaptic neurons) or inhibitory (the signal decreases the action potential of postsynaptic neurons). In the brain the proportion is about 20\% of excitatory neurons, for 80\% of inhibitory. The excitatory neurons signals are stronger, compensating the inhibitory signals. This is not modelled in the model, where all neurons are considered excitatory.\\
	The Dirac form of the interaction also allows to not store the full history (or at least a partial one as there is a reset of the potential over a certain value anyway) of spikes. This is important as it allows not to preoccupy about what happened to the network before the beginning of the simulation, and we can then assume that whatever initial state the network is given is its full state. This is not the case for other kinds of point processes, such as Hawkes processes, for which a stationarity hypothesis and a warming up time are necessary in order to have believable data from the simulation [INSERT REFERENCE HERE].\\

	Continuing with the description of the equation terms, there is a dependence of the potential of the neuron i with the potential of all other neurons in the system and with an external electrical current yet to define. Both of them come from the analogy between a neuron's membrane and an electric circuit and from which the Integrate\&Fire model has been derived. The external current represents the effects of external parts of the studied system. The effect of a neuron potential on all other neurons potentials comes from the link that exist between neurons. As the graph is considered in this model to be fully connected, all other neurons in the system have an influence on all other neurons. This joint between neurons (named axons and dendrites) are modeled in the Integrate\&Fire view as simple ohmic conductances.\\
	These two terms will be considered as equal to zero during our analysis, for two reasons. First, in terms of modelling, it is fair to consider we are looking at the whole system, and so there is no need for an external input current. This has no sense biologically speaking, as all sensations are thr fruit of electric currents emitted by the neuronal sensors in our body, but all neurons are considered to be their own generators here, and we are not interested in the response to the system to external stimulis but rather in the natural behaviour of the system. [TYPICAL VALUES OF BETA THAT WOULD JUSTIFY CONSIDERING It AS NULL?]. The second reason comes from the reasons of the study of this model. Having immediate spiking and only excitatory interactions in the model introduces a strong possibility of a "blowing up" of the system in finite time. The conditions necessary for the occurrence of this phenomenon has been examined in [INSERT CITATIONS] and in this document. The issue lying in the "jumps" of the system, the external current and the potential dependency turn out to be an unnecessary difficulty in the model, so we will simply not consider them from now on.\\

	Last but not least the two terms that describe the evolution of a neuron's potential, independently from what happens in the rest of the system. The $\lambda$ term comes from the natural tendency of the membrane to let go some of its accumulated potential. On the other end the $\sigma\mu_i$ term is a noise (actually a white gaussian noise) that is supposed to be independent from neuron to neuron.\\
\subsection{The real equation}
	That being posed, we can now pose the real equation under study in this report.\\
	\[
		V_t^i=V_0^i+\int_0^tb(V_s^i)ds+\sigma W_t^i+\sum_{j=1}^NJ^{j\rightarrow i}M_t^j-M_t^i(V_T^i-V_R^i)
	\]
	Here b is Lipschitz continuous, and $\forall V, b(V)=-\lambda(V-a), (\lambda,a)\in\mathbb{R}_+$. This function will make the potential drift towards the value a. The J term models the interactions between neurons, their values depends on the number of neurons in the system and which neurons are actually involved in the interaction. \\
	Throughout the event several values of interaction have been tested. They generally are Bernoullis variables, fixed as at the creation of the system.\\
	In this paper we are going to focus on what sets of parameters favors the apparition of a blowing up of the system. The influence of the interaction term is a big part of the study, but the influence of other parameters, such as the b function, the noise, and the topology of the network are also looked at.\\

	\subsection{Motivations}
	In the deterministic case, the blow up is quite easily defined by the limit to a time value t of the variations in the spike rate equals to infinity. This 