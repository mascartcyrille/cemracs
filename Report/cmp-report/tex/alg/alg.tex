	In this chapter we aim at developping and implementing an algorithm for the simulation of a system driven by the mean-filed equation described before, and for a large number of nodes, in reasonnable times. The mean-field equation makes sense for an infinite number of actors and the actual number of neurons in most living beings is tremendous anyway (1e5 in drosophilia and 86 billions in human beings for instance).\\
	The usual way of carrying such a numerical simulation is to compute the finite difference integration of the associated diferential equation. There are several well-known methods based on this discrete-time approach, such that Euler or Runge-Kutta, but they all suffer from the same drawbacks: namely, the computational cost which is of order $N^2$, meaning the number of operations necessary on order to finish the simulation is of order the square of the number of neurons.\\
	Indeed, assuming there is on average $Nc\nu$ spikes per second (N the number of neurons, c the probability of connection between two neurons, $\nu$ the spike rate = on average a neuron emits $\nu$ spikes per second), and $\delta t$ is the time step, then there is on average $\frac{cN}{\delta t}$ updates per second (at each time step, only the spiking neurons and the post-synaptic ones are updated), but the average time elapsing between two spikes is $\frac{1}{Nc\nu}$. In order not to introduce errors due to the dynamical effect of a single spike, the time step should be so that the probability of receiving more than one spike in $\delta t$ is negligible. Put it otherwise, $\delta t<<\frac{1}{Nc\nu}$, and so $\text{average number of updates per second per neuron}>>N^2c^2\nu$, hence a complexity of order $N^2 per neuron$.\\

	In order to exceed this limit, we considered a different approach. Indeed, in realistic conditions the neurons emit at low rates but with a high variability in the time intervals between successive spikes, therefore a discrete-time algorithm will spend most of its time updating the state of the neurons, while the evolution of the potential of the membrane follows a deterministic law between two successive spikes. If the dynamic of a system is driven by these spikes (or more generally any instantaneous abstract event), then a more efficient algorithm can take advantage of the determinism of the state of a neuron between two spikes to interpolate its potential whenever a spike occurs, and only update the system when a new spike is emitted.\\
	Such an approach is called event-driven, and this is what is discussed hereafter. The complexity of this kind of algorithm is often linear in N, as a neuron influences an average of $Nc\nu$ other neurons per seconds, to be compared with the $N^2c^2\nu$ obtained before because of the very small time step necessary for not introducing a divergence too important. The simulation is also an exact solution of the equations driving the system, in that there is no approximation in the time of an event (except for the necessary rounding due to the limitation of real number representation on computers). This kind of algorithm is very effective, but much more complex to implement because of the event handling part.\\

	Altough this approach seems promising, it is not always appliable as so. One of the necessary conditions if the deterministic path from one state to another, and in the case of systems described by stochastic equations, this hypothesis may not be fulfilled as we are going to see shortly after.

\section{Definitions}
	With this approach some definitions given before are no longer appliable to the system.\\
	The threshold is then defined as:\\
		At any given time, any neuron i of potential $V_i$ has a chance of firing which is function of
		\begin{equation*}
			f(V_i)=S*(Pos(V_i-V_T))^E\text{, where }Pos(x)=\begin{cases}x & \text{if }x>0\\V_R & else\end{cases}
		\end{equation*}
	$V_T$ is chosen equal to one, and $V_R$ is equal to zero for all neurons (for simplicity purposes), but they could be chosen more randomly. A threshold value too low (too close to the reset value) is problematic, as it means that potentials are going to reach their threshold quickly after a neuron has spiked (in which case the system is "stuck" in a perpetual series of spikes). By design only one neuron can fire at a given time (the spike trains are point processes), and if a cascade is cannot normally happen (except in cases where some values are rounded to zero due to the limitations in floating point precision, but more on that later) that does not solve the issue of blow-up, as a similar phenomenon can still occur (the rate will not tend to infinity, still it tends to very high values). The blow-up is indeed newly defined as (Pertinence de comparer \`a N lorsque tous les neurones ne spikent pas ? Pourquoi pas plut\^ot quelque chose du type $1/\delta_N->\infty$, avec $\delta_N$ l'intervalle entre deux spikes ?):
	\[
		\frac{1}{\delta_N}>Constant\text{, typically N}
	\]
	where $\delta_N$ is an interval between two spikes (or a mean interval, or a moving average). The constants S and E are chosen so that the chances of fire are high even for values of the potential low above the threshold (typically, $S=10^5\text{ and }E=5$, while values of potentials at spiking times are around [CALCULER VALEUR PRECISE, DE MEMOIRE 1.4]).

	The system is driven by a stochastic PDE and discontinuities are randomly introduced depending on the value of parts of the system. There are two common ways of simulating a stochastic PDE. The Euler-Maruyama method for numerical approximation of stochastic differential equations results in the construction of a Markov chain on the interval $[0,T]$ of simulation. While quite simple to set up and understand, it is wastefull for processes that spend a lot of time not changing, in this case not spiking. In addition, the resolution of the time interval shall be low enough to capture the meaningful variations in the system, here the moments of spikes and the blowing-up behaviour, as well as to keep the simulation precise enough. Spikes are diracs, discontinuities of the system, and the blow up happens when the firing rate tends to infinity, or to spell it otherwise, when the time interval between spikes tends to zero.\\
	The second method is the thinning, which is a common method for generating random numbers from distribution of not well defined cumulative distribution function \url{http://www.aip.de/groups/soe/local/numres/bookcpdf/c7-3.pdf}. Here the stochastic process is the network of neurons, and its intensity directly depends on the potentials of the neurons, following the function $f:\mathbb{R}\rightarrow\mathbb{R}^+$ described above. In this method two numbers (for the one dimension case) are generated, $(t,u)\in\mathbb{R}+\times[0,1]$. They represent a point in the plane and depending on whether the point can be placed under the curve of the desired cumulative distribution function or not the point will be declared accepted or rejected. In order to achieve this in practice the value of $\frac{f(x)}{f_{max}(x)}$ is compared to a number uniformly generated between zero and one. The approximation function is used in order to increase the probability of generating a point under the curve (on the full spectrum of real positive numbers, the chances are null).\\

	\begin{figure}
		\begin{center}
				\begin{tikzpicture}
					\draw [-latex] (-0.1,0) -- (7,0) node[right] {t};	% X-absciss
					\draw [-latex] (0,-0.1) -- (0,4) node[left] {N(t)};	% Y-absciss

					
				\end{tikzpicture}
			\end{center}
			\caption{Illustration of a counting process}
			\label{fig:count-proc}
	\end{figure}
	\todo{INCLUDE A GRAPHIC EXAMPLE OF THE PROCEDURE, ALIKE THE ONE DRAWN ON BOARD}

	The $f_{max}$ here can be computed by a simplified, limit in time version of the model. Indeed, a rough estimate can be created by dividing the equations in sums of which the maximum value in time will be taken.
	\[
		f_{max}=\max_t(a+\exp^{-\lambda t}(y_t^i-y_S^i))+\max_t(\sigma\mathbb{N}(0,\frac{1-\exp^{-2\lambda t}}{2\lambda}))
	\]
	The maximum proposed here is not correct. Indeed, there are no boundaries for a normally distributed random number, hence the white noise cannot be bounded and the variations for the potentials are in $\mathbb{R}\cup\{-\infty,\infty\}$... But! The chance of generating a number of absolute value larger than the variance decreases the farther away this number is from the variance. Thus it is possible to consider, with a certain degree of confidence, that no numbers will be generated outside of a predefined interval, the bounds of which will constitute our maximum. More precisely, given a random variable X following a normal law $X~\mathbb{N}(\mu,\sigma^2)$, then it is possible to compute $P(\mu+k\sigma\leq X)$. The table \hyperref[repartitionFunction]{\ref{tab:repartitionFunction}} gives values of the chances of generating a number outside the interval $[\mu-k\sigma,\mu+k\sigma]$.\\
	\begin{table}
		\centering
		\begin{tabular}{cc}
			\textbf{k} & \textbf{chance} ($\approx$)\\\hline
			1 & 3.173105e-01\\
			2 & 4.550026e-02\\
			3 & 2.699796e-03\\
			4 & 6.334248e-05\\
			5 & 5.733031e-07\\
			6 & 1.973175e-09
		\end{tabular}
		\caption{Chances of generating a number of absolute value k times above the variance, knowing that $P(X < \mu-k\sigma OR X > \mu+k\sigma)=2-2\phi(k)$ (computed with R using \emph{pnorm} for a centered normalised law)}
		\label{tab:repartitionFunction}
	\end{table}
	In the current implementation k has been fixed at 5, as the number of neurons will hardly be higher than $10^5$ for memory reasons (the graph of interaction takes $p\times N^2\times 64$ bits of ram memory, p being the probability of connection between two neurons in a Erdos-Renyi graph, 64 being the number of bits necessary for representing an integer on a typical computer nowadays and for $N=10^5$ this value is higher than the typical amount of ram available on a computer, even for dedicated comptuting machines). There is also an influence of the number of spikes (accepted or rejected) generated during the simulation: each time the simulator decides whether the spike is accepted or not the true value of the potential is computed therefore the value of the noise is computed and there is a chance of generating a normally distributed number higher than the bound we have set.\\

	So tosummarize, we have chosen to use a thinning procedure to compute the solution of the stochastic partial differential equation described in the \ref{sec:Model}. The thinning procedure necessitates the use of an approximation function, which must be in any point higher than the function to simulate/compute. Even though a part of our model is a gaussian white noise, which is unbounded, it is still possible to use a pseudo-boundary for the noise, that is to say a number that will constitute an upper-limit with a certain degree of confidence. The limit directly depends on the confidence interval we want for our simulation, so this solution is both easy and flexible. Computing this pseudo-boundary necessitates only values that are necessary to compute the value of the gaussian white noise, so this solution does not increase the amount of computations needed. Actually it is much less expensive, in processor time, to compute the value of the upper-limit, as the actual value of the variance (which relies on an exponential in our case) is not needed (a maximum in time of the variance is enough, and adds in the confidence). Also, it is important to remark that even if we have focused on giving an upper-bound to the noise, there are other parts in our model that are approximated too, and so values of the noise not too much above the upper-limit may not make our approximation function $f_{max}$ lesser than the actual potential, so the solution is robust even to small errors.\\

	Finally, we can remark that we are sampling the noise anyway, meaning there is no way for us to know that even if the noise at the time of spike is indeed in the boundaries, it has not crossed the boundaries during the time inbetween two consecutive spikes. So what if there are errors in the evaluation of the noise? Two cases emerge. First, there is a bad approximation of the noise of the spiking neuron. So this neuron is certainly the good one to pick for a spike but it may have spiked a bit earlier if we had the information of the real value of its potential. The second case is more criticial, as this is the case where a neuron has been chosen for spiking, but the potential of one of the non chosen neurons is higher than expected, meaning it had actually more chance to spike. Of course the neuron we have chosen may actually still be the good one, then the error does not matter at all, the next computation of the potential shall rectify the mistake. Yet, even if we imagine that having another estimation for the potential would have changed the spiking neuron, given that we are dealing we at minimum 10,000 neurons, and more probably 100,000 neurons, and generating around the same number of spikes, having even a handfull of mistakes would not mean a large deviation of the final result (if a neuron should have spiked but does not, and this because of the noise, not the configuration of the network or the intensity of the spikes or whatever, then it will spike just a bit later, and excepting in the case where we speak about very critical neurons of very specific networks, this kind of mistakes can be considered as a good tradeof for speed).\\

	At this stage we have a first draft for the thinning procedure algorithm, but we can improve it a lot. For now we have focused on improving the efficiency of and discussing about the quality of the approximation function $f_{max}$, but f is not the real equation simulated here, it just helps defining a probability for a neuron to spike, depending on the value of its potential. But as the potential evolves in time, the approximation is always false, and by a bigger margin at the beginning of time than at infinity, since the approximation function is built using the values for $t\rightarrow\infty$. Unfortunately, the values of t (the x-axis part of the points generated for the thinning method) have a lot more chance to be small as they are generated using an exponential distribution (we are dealing with poisson processes so the spikes must be exponentially distributed in time [enfin ici du moins en l'occurrence c'est en temps]). This is also an issue for the random generation, as pseudo-random number generators cycle and generating more unuseful numbers may lead the generator to cycle.\\

	A common solution to avoid this is to bound the research of accepted points in time: we define a time interval of research and then look for points in this interval. Once a certain condition is met (for instance here every time we have an accepted point or when the time for the next potential spike is greater than the time limit) we stop or change the time interval. This way the approximation function is way closer to the real function and we can drastically improve the amount of accepted points.\\

	\todo{INSERT HERE GRAH OF THINNING METHOD WITH TIME INTERVALS}

\section{Algorithm in pseudo code}
	Finally here is, in pseudo code, the algorithm used for simulating the equation driving our model.\\

	\begin{algorithm}
		\caption{Pseudo code of the thinning algorithm used for simulating the system}
		\label{alg:pseudo-code}
		\begin{algorithmic}
			\State Initialize all parameters
			\Repeat
				\Repeat
					\State determine an interval $[t_{n-1},t_n]$ on which sampling
					\State compute the array of $f_{max}(Y_{t_{n-1}})$ and $\sum f_{max}(Y_{t_{n-1}})$ on interval $[t_{n-1},t_n]$
					\State $t_n\sim t_{n-1}+\mathscr{E}(\sum f_{max})$
				\Until{not in good interval or all $f_{max}$ are at 0}
				$u\sim\mathbb{U}([0,1])\rightarrow \mathbb{P}(\text{spiking neuron is neuron i})=\frac{f_{max}^i(Y_{t_n}^i)}{\sum_j^N f_{max}^j(Y_{t_n}^j)}$
				$u\sim\mathbb{U}([0,1])\rightarrow \mathbb{P}(\text{accepting spike of neuron i})=\frac{f^i(Y_{t_n}^i)}{f_{max}^i(Y_{t_n}^i)}$
				\If{ spike is accepted }
					update the potentials of all postsynaptic neurons
				\EndIf
			\Until{do not have the good amount of accepted spikes}
		\end{algorithmic}
	\end{algorithm}

\section{Improving efficiency}
	\todo{PENSER A METTRE UN PEACH SUR OPENMP, LES ALTERNATIVES ET PK ON (JE) L'A CHOISIS}
	This section will mainly focus on speed and memory usage. The algorithm presented above works perfectly except that the computations involved here can be very long in processor time, and that the amount of memory for running it is potentially tremendous. On the speed part, the algorithm has been implemented in C and optimised using -O3 in order to take advantage of the gain of speed of the low level languages. Dedicated libraries (here openmp) can and have been used in order to improve the speed of some parts of the simulation, in the parts where a state variable needs to be changed for all or a large amount of neurons.
	Some specific interaction cases, like full connection (including selfconnections), complete interaction graph and independence (no connections) are encoded so that the connection graph is not needed, improving speed and memory consumption. but on the generic case, even though the full matrix of interactions is not stored (only the relevant parts), the memory for storing the interaction graph takes around $p*N^2$, where p is the probability of interaction and N the number of neurons. For even $10^5$ neurons that makes about 1 GB, given 1 byte is enough to store the index of neurons (and the addresses in memory)(spoiler: it is not, and takes rather 4 times more) and with a probability of connction of 0.1... where the probability of connection was 1 in the mathematical papers.\\

	Still, when the interaction graph is too big but there is no way to skip the generation of the interaction graph, there is a way to save a lot of memory by storing seeds instead of a boolean about whether there is an interaction or not. When generating an interaction graph with a random connection probability, for each neuron, instead of storing an array containing alll the postsynaptic neurons, one can rather store the state of the random number generator (for instance, in Mersenne Twister, it is about 128 bits, and it is one of the largest state for a classical random number generator) just before randomly chosing the postsynaptic neurons. This way, each time a neuron is spiking, one can regenerate the same graph, and more interestingly the specific part of the interaction graph of interest (that is to say only the postsynaptic neurons of the spiking neurons, and no the entire graph of interaction). While a lot slower, this method is probably one of the most efficient in memory, taking advantage of the pseudo character of the random number generation in computer science.\\

	This method is also parallizable with openmp or any library alike it, but it is more difficult to achieve if one want to guarrantee the reproducibility of the results. The parallelization is possible because if one cuts the array of the postsynaptic interactions in k parts, then k random number generators can be used for generating the interaction graph. The issue here is on the initialization of the random number generators, as we want to avoid the case where there is an overlapping in the sequences in use by two threads at the same time. A RNG like the Mersenne Twister, with a very large pseudo period is great for this purpose, as it allows to cut the pseudo period so that two processes correctly seeded will never overlap. This considerations are also needed if one wants to run several simulations in parallel. [METTRE PUBLI BENNIE]

\section{Implementation}
	As said before, the algorithm was finally implemented in C (and prototyped in Java). There are several reasons for that. The C language is close enough to the machine language to be one of the fastest possible and allows a precise management of the memory usage. Most compiler (as gcc, the one we used) also have options for improving the speed and memory consumption of the program. These options are also supported by the version of the Mersenne-Twister random number generator used in the implementation. There are two of them, on for integer generation and one for double precision generation, and they can be found at \url{http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/SFMT/index.html}. O this site there are more information about Mersenne-Twister generators in general, as this page has been created and is maintained by one of their creator, Makoto Matsumoto.\\

	The computations at stake here involve potentially both very low and very high values. For instance the time of spikes are exponentially distributed. They are obtained using an exponential distribution of parameter the sum of all the approximation functions (on the current interval of work). This value can typically raise up to $10^5$ or $10^6$ (consider the same number of neurons, their potential close to the threshold).\\

	For this reason some 

\section{A word about the rng}
	Mersenne twister, and not xorshift because the mersenne allows for a reproduction of the simulations, which is also necessary for a part of the algorithm. It is well known, and has a huge period which is important for a part of the algorithm. Also there are a lot of good implementations, some of the creator itself who actively update them when bugs or improvements are found. The method also allow for good generation of random real numbers (not only integers)

	A related subject is the distribution followed by the random numbers. The algorithm presented earlier needs several random numbers from various distributions, none of them being too exotic (uniform numbers with arbitrary upperbound and normal numbers centered on zero with arbitrary variance), but as the library used only provide uniform random series of 32 or 64 bits and random floating point numbers in [1,2) or {[0,1], [0,1), (0,1], (0,1)}, we must implement a way to generate the numbers drawn from our arbitrary distributions. In both cases a sampling method (again) is used, and we are going to describe them.

	First the uniform case. We have a random integer generator, and we assume it gives perfectly random numbers in $ {0, 1, ..., M} $, while we want uniform numbers in $ {0, 1, ..., U} $. A common method to achieve this is to use a modulo: $ \mathbb{U}([0, M]) mod[U+1] $. The issue here is that unless M is a multiple of $ U+1 $, the uniformity of the numbers is lost using this method. The case in which the method works can be used as a trick for guarrantying uniformity though. Indeed, if M is not a multiple of $ U+1 $, there must exist one that is lower than M but close anyway. Knowing that, we can simply take any number that is lower than $ U+1 $ and in the rare cases a number greater than $ U+1 $ is drawn, we just have to reject it and draw another one. Of course the maximum value M must be quite high, compared to $ U+1 $ in order for this method to be effective. For instance, if $ U+1= $, there is a 49\% of rejection. If the rest of the euclidean division of M bu $ U+1 $ is U, the 